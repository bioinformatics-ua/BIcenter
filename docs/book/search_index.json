[["index.html", "BIcenter: A collaborative Web ETL solution Preface", " BIcenter: A collaborative Web ETL solution J. R. Almeida, L. Coelho and J. L. Oliveira 2021-10-18 Preface "],["introduction.html", "Chapter 1 Introduction 1.1 Main requirements", " Chapter 1 Introduction BIcenter is a web-based platform that allows the building and management of ETL pipelines, by non-IT users, in a multi-institution environment. Each institution manages and mantains ETL tasks and provides the resources for the execution of the associated tasks. Thus, each institution owns its private data sources, servers for ETL task execution and a task scheduler that allows periodic execution. In order to provide access and management control of ETL tasks and institutions, there are four distinct types of users: Administrator: Entity that moderates the platform. This actor has permissions to create and delete institutions. Resource Manager: Entity that manages private data sources and execution servers. This actor has permissions to create and delete private data sources and execution servers, within specific institutions. Task Manager: Entity that builds and executes ETL tasks. This actor can create and configure ETL tasks, within specific institutions. Data Analyst: This actor has permissions to inspect task execution history, namely the resulting data, execution logs and performance metrics. 1.1 Main requirements Information Security Since ETL tasks parse and handle sensitive data that belongs to a particular institution, the system must be designed and implemented taking in account these security issues, namely user authentication, access control, data protection and isolation. System Reliability Considering the periodic execution of ETL tasks, it is important to ensure that each execution is correctly initialized, started, motorized and concluded. When some fatal error occurs during an ETL task execution, the system must be able to handle the error and successfully conclude the execution. Solution Scalability Since a complete ETL tool typically encompasses a wide variety of components, it is crucial to build an agile approach to the development and integration of new ETL components. "],["system-implementation.html", "Chapter 2 System Implementation 2.1 Requirements 2.2 Architecture 2.3 ETL SDK", " Chapter 2 System Implementation This chapter contains the description of the main aspects of BIcenter implementation. 2.1 Requirements The main goal of this application was to allow the building and management of ETL pipelines, by non-IT users, in a multi-institution environment. Therefore, some functional requirements were were considered to implement a proper and reliable solution. Each institution manages and mantains ETL tasks and provides the resources for the execution of the associated tasks. Thus, each institution owns its private data sources, servers for ETL task execution and a task scheduler that allows periodic execution. In order to provide access and management control of ETL tasks and institutions, there are four distinct types of users: 1) Administrator, entity that moderates the platform, and it has permissions to create and delete institutions; 2) Resource Manager, entity that manages private data sources and execution servers, and it has permissions to create and delete private data sources and execution servers, within specific institutions; 3) Task Manager, entity that builds and executes ETL tasks, and it can create and configure ETL tasks, within specific institutions; and 4) Data Analyst, actor with permissions to inspect task execution history, namely the resulting data, execution logs and performance metrics. The functional model was derived from the identification of all key components from a top-down analysis of the system requirements. Figure 2.1 illustrates step by step all actions and interactions between the main actors in order to build and execute ETL tasks and to analyze the output results. Firstly, the administrator must create an institution. A resource manager with access to the institution can create and configure all desired private data sources and task execution servers. Thereafter, a task manager can build and configure the ETL task and then schedule it for periodic or non-periodic execution. At the configured times the task will be sent to the execution server and executed. At the end of the execution, a notification will be sent to the data analysts, so they can check the execution results. Figure 2.1: System workfow to build, manage and execute ETL tasks. 2.2 Architecture The architecture considers four different tiers: 1) Application tier controls all application functionalities and maintains the system business logic; 2) Data tier is responsible for the maintenance of the private data sources; 3) Processing tier has the duty of executing and monitoring ETL task executions; and 4) Client tier is responsible for the solution presentation and page rendering. Figure 2.2 illustrates this architecture. Figure 2.2: Components diagram of system architecture. The system logic is built upon five different controllers: 1) RBAC controller provides user identity and evaluates access requests to resources; 2) Institution controller allows the creation and destruction of institutions, and resource allocation in institutions; 4) Task controller enables the creation, configuration and destruction of ETL tasks; and 5) Execution controller uses Kettle and Carte servers, so it can build, remotely execute and monitor ETL tasks. Data Integration (DI) Software Development Kit (SDK) seeks to bridge the gap between Kettle and the stored information in BIcenter database (DB). It provides methods to build Pentaho’s ETL processes according to the stored information, and also to execute them. Nevertheless, task execution is a periodic process. Therefore, Execution Scheduler manages the task execution scheduling. When the appropriated time arrives, a Execution Job is triggered. That job will communicate with DI SDK so that the given task is indeed executed. SVG controller maps between images and components, with the intent to build the visual pipeline. BIcenter Web client adopted Model-View-Controller (MVC) architectural pattern. This pattern divides the web application in three different components: Model: represents the knowledge and data in an application. It has the responsability to respond to information requests, proceed to information changes according to given instructions requests, and to notify observers in event-driven systems when information changes. Typically, the application data is stored in a database. View: it represents the user interface. The View updates the UI upon changes in the Model, by rendering the data into the suitable UI form. Controller: it handles events that occurs in the View, such as user interactions, and updates the Model accordingly. 2.3 ETL SDK The ETL Task Editor was idealized to allow users to build a visual representation of the desired ETL pipeline. This editor must be able to process a similar structure to the ones used by the desktop ETL tools and generate the correspondent visual representation of the ETL task. MxGraph was used to build the ETL pipeline editor, and this Java/JavaScript diagramming library enables the building of interactive graphs. A graph consists in a set of cells. A cell can either be a vertex or an hop. Thus, a graph is formed by a group of vertices connected by edges. The vertices correspond to the ETL steps and the edges correspond to the ETL hops. Hence, in order to exhibit the desired task within the mxEditor, it is necessary to translate the task to the corresponding mxGraph object. GraphDecoder is responsible for creating a mxGraph and defining the appropriated model, according to the given Task. To insert vertices and edges in the graph model, a transaction must be created (beginUpdate and endUpdate). This is required for the model to remain in a consistent state. A default parent is automatically created and represents the first child of the root cell in the model. Subsequent elements must be added to the default parent. The ETL SDK was built on top of PDI SDK. Kettle contains a rich set of data integration functionality that is exposed in a set of data integration tools. However, we can also use Kettle as a library in our own software and solutions. Pentaho Data Integration can be used as a Java API composed by three main components: 1) Core, that contains the core classes for Kettle; 2) Database, that contains the database-related classes; and 3) Engine, that contains the Kettle’s runtime classes. Figure 2.3 explains step by step how an ETL task is executed. The initialization of the Kettle environment loads all available plugins, initializes the logging environment and set up and reads the system variables. After the environment initialization, the transformation metadata is loaded and a transformation engine object is instantiated. Then, the execution is prepared and the transformation threads are started. Finally, because the whole transformation runs multi- threaded, it waits until all processing is completed. Figure 2.3: ETL task execution flowchart. In Kettle, an ETL process can be represented by six classes [31]: TransMeta: is the class that defines the information about the ETL process and offers methods to save and load it from XML, as well as methods to alter an ETL process by adding/removing databases, steps, hops, etc. Trans: represents the information and operations associated with the concept of an ETL process. It can loads, instantiates, initializes, runs, and monitors the execution of the ETL process. DatabaseMeta: defines the database specific parameters for a certain database type. StepMeta: is the class that defines the information about a ETL process’s Step. TransHopMeta: defines a link between two steps in an ETL process. BaseStep: represents the information and operations associated with the concept of an ETL process Step. It offers initialization, row processing and step clean-up methods. Initially a TransMeta must be properly configured with all proper DatabaseMetas, StepMetas and TransHopMetas. TransDecoder is responsible to create a TransMeta and define all underlying information, according to the given Task. GenericStep is a class that has a generic algorithm to encode or decode a given Step to or from a Kettle’s StepMeta. In order to provide interface segregation, TransDecoder must use the StepDecoder interface that only provides the GenericStep decoding method. After having a correctly configured TransMeta, it can be executed with the associated Trans object. TransExecutor is a singleton responsible for the initialization, execution and monitoring of the Trans object. Moreover, it writes and stores the execution logs, step measures and status, and the resulting data in real-time. To accomplish this, listeners are coupled to the Trans and Steps objects in order to obtain the results and metrics throughout the transformation’s execution. "],["software-user-manual.html", "Chapter 3 Software User Manual 3.1 Initial views 3.2 Institutional features 3.3 ETL Task Editor", " Chapter 3 Software User Manual This chapter presents the main interfaces of BIcenter, aiming to help users to navigate through the system. 3.1 Initial views The login page presented in Figure 3.1 allows users to be authenticated using their credentials. This can be connected with the institution LDAP, which provides a central place to store usernames and passwords. Figure 3.1: Login page. After the authentication process, the user is redirected to the application’s home page represented in Figure 3.2. This page contains all the institutions that the user belongs to. In this case, this user has permission to create a new instance of an institution in the application using the modal illustrated in Figure 3.3. Figure 3.2: Home page after login with all institutions assigned to the user. Figure 3.3: Modal to create new institution. 3.2 Institutional features The configuration of a data source is illustrated in Figures 3.4 and 3.5. Firstly is created the data source instance in the institution, and then, the details of this connection are inserted in the modal represented in Figure 3.5. Figure 3.4: Creation of connection to a data source (first step). Figure 3.5: Modal to insert information regarding the new connection to a data source (second step). The connection to the remote server follows a similar flow. This configuration is illustrated in Figures 3.6 and 3.7. Figure 3.6: Creation of connection to a remote server (first step). Figure 3.7: Modal to insert information regarding the new connection to a remote server (second step). Finally, the ETL tasks are also created for the institutions. This feature redirects the users to the ETL Task Editor, in which they can design and implement an ETL pipeline using the web interface. The creation of a new task can be done by using the option represented in Figure 3.8. Figure 3.8: Creation of a new ETL task (first step). 3.3 ETL Task Editor The ETL Task Editor allows users to create an ETL pipeline by dragging and dropping ETL components. Figure 3.9 shows an overview of this web editor. Figure 3.9: Overview of the ETL Task Editor. Figure shows an example of an ETL pipeline implemented in the ETL Task Editor using the four most common ETL components. Figure 3.10: Simple example of an ETL pipeline represented on this editor The components available to implement these ETL pipelines are available on the left menu. Part of this menu is represented in Figure , which is expanded the components for input, output and transformations. Figure 3.11: Overview of part of the ETL components currently deployed in the system. The navigation bar illustrated in Figure allows the uses to operate over the ETL Task. This menu is divided into sub-menus: 1) step, which contains the features to configure each ETL component in the pipeline and analyse the input and output of each step; 2) execution, which defined if the ETL task will be executed locally or in a remote server; edit, contain the editing usual features, such as cut, copy, paste, delete, undo and redo; and 4) select, which is related with the drawing features. Figure 3.12: Main features of the ETL Task Editor. "],["guidelines-for-developers.html", "Chapter 4 Guidelines for Developers 4.1 Branching Convention 4.2 Adding an REST API endpoint 4.3 Adding web view 4.4 Adding new PDI step", " Chapter 4 Guidelines for Developers In this chapter, it is described the main guidelines for contributing to BIcenter. 4.1 Branching Convention After some consideration, we decided to implement naming conventions in the branches being created. We followed a scheme similar to the one referred at http://stackoverflow.com/a/6065944 Each branch name is composed of the following: category/name The possible categories are listed below. Category Description bug Bug fixing imp Improvement on already existing features new New features being added wip Works in progress - Big features that take long to implement and will probably hang there junk Throwaway branch created to experimentation The name should be concise, and directly represent what the branch solves. Some examples: bug/issue234 bug/fixeditdb new/statistics junk/tryingboostrap3 4.2 Adding an REST API endpoint Create the endpoint at app &gt; controllers, either on one of the existent JAVA files or a new one if it handles a completely different topic/task, yet to be addressed. Add the respective endpoint URL to: conf &gt; routes, so that the system knows that endpoint exists; app &gt; controllers &gt; Application.java &gt; javascriptRoutes(), so you can use this URL dynamically at JavaScript, regarding frontend code. Since the structure of this project includes both Frontend and Backend, when you create a REST API endpoint, you’ll probably consume it on some frontend feature. Here’s how to do that: At app &gt; javascripts &gt; services, there is a collection of JS files that have all the encapsulated logic responsible for communicating with the REST API: one file for each major entity or group of actions. So, in one of these files or a new one, add the function that handles the communication you need with the REST API through your newly developed endpoint. At the JS controller level of your functionality, you call the function specified in the previous step with the necessary arguments and information. 4.2.1 Example This example assumes that there isn’t an endpoint capable of providing information about all the existent institutions. So the purpose is to create such endpoint and provide a function that allows us to consume it on the frontend. Hence, there are 2 phases: the creation of the REST API endpoint and the creation of the necessary utility to consume it on the frontend. 4.2.1.1 Creation of REST API endpoint Because the endpoint we want to create has the purpose of returning the information about all existent institutions, it should be placed at app &gt; controllers &gt; InstitutionController.java, with some code like this: @Security.Authenticated(Secured.class) @CheckPermission(category = Category.INSTITUTION, needs = {Operation.GET}) public Result getInstitutions(){ String email = session().get(&quot;userEmail&quot;); List&lt;Institution&gt; institutions = institutionRepository.list(email); ObjectMapper mapper = new ObjectMapper(); SimpleModule module = new SimpleModule(); module.addSerializer(Institution.class, new InstitutionSerializer()); module.addSerializer(Task.class, new SimpleTaskSerializer()); module.addSerializer(Server.class, new ServerSerializer()); module.addSerializer(DataSource.class, new DataSourceSerializer()); mapper.registerModule(module); Json.setObjectMapper(mapper); return ok(Json.toJson(institutions)); } After creating the endpoint, we need to make it discoverable (be available to the outside world). To do that, we add its URL to: 1. conf &gt; routes: ... GET /institution/list controllers.InstitutionController.getInstitutions() ... app &gt; controllers &gt; Application.java &gt; javascriptRoutes(): public Result javascriptRoutes() { response().setHeader(Http.HeaderNames.CONTENT_TYPE, &quot;text/javascript&quot;); return ok(JavaScriptReverseRouter.create(&quot;jsRoutes&quot;, ..., routes.javascript.InstitutionController.getInstitutions(), ... )); } 4.2.1.2 Creation of utility function to consume the REST endpoint This second phase explains how to create the referred utility function so we can more easily consume the developed endpoint. Since it’s an institution-related method, we will be adding the following utility function to app &gt; javascripts &gt; services &gt; institution.js. Institution.getInstitutions = function (callback) { jsRoutes.controllers.InstitutionController.getInstitutions().ajax({ contentType: &#39;application/json; charset=utf-8&#39;, success: function (response) { if (callback) { callback(response); } }, error: function (response) { console.error(&#39;Error in Institution service&#39;, response); } }) }; This consumes the endpoint and, on success calls the specified callback function; otherwise (on fail) displays an error message on your browser’s console. After this, the final part is to consume this utility function, which can also be called a service. A simple example is to use the service on your javascript file that bears the “backend” responsibility of your UI component/view, in a similar way to the following code: Institution.getInstitutions(function (institutions) { // do whatever you need with the returned information }); 4.3 Adding web view If you want to create an entirely new base schema (a view), you first need to add a base template name &lt;name&gt;.scala.html to app &gt; views. You also need to make sure that you have an endpoint on JAVA code that handles your request and returns this web view (the “backend” process is similar to create a REST API endpoint). If you just want to create a new UI stage, based on an already defined view, follow these steps: 1. Create an endpoint (and register it) that returns the base view you want to use. At app &gt; assets &gt; javascripts, create the controller and view associated with your new UI stage (the view JS file handles the stuff UI related and the controller handles the stuff Backend related). At app &gt; assets &gt; templates, create a file named &lt;name&gt;.handlebars where you’ll insert the UI code that will be dynamically added to the main div container of your base web view. After all these files are ready, you need to make sure the framework knows the path to everything you created, so you’ll need to add the paths to your view and controller javascript files in the file app &gt; assets &gt; javacripts &gt; main.js. Finally, you’ll need to add the RegExp handler that will assemble the resources you need (variables and controllers) at app &gt; assets &gt; application &gt; application.js. 4.3.1 Example This example is going to be divided into two big parts: the creation of a new view from scratch and the creation of a UI component (through handlebars). Let’s take as an example the creation of a dashboard page, given the fact that we need to create a new base-view from scratch. NOTE: if you just want to create a new UI component, with handlebars, jump to the second part. 4.3.2 Creation of a new (base) view To create a new view to use as a base to new UI stages, you first need to add the HTML template. So, add your view structure to a file named home.scala.html, for the sake of this example, at app &gt; views: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge&quot;&gt; &lt;!-- Tell the browser to be responsive to screen width --&gt; &lt;meta content=&quot;width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no&quot; name=&quot;viewport&quot;&gt; &lt;title&gt;BIcenter&lt;/title&gt; &lt;!-- Boostrap Select2 --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/select2/select2.min.css&quot;)&quot;&gt; &lt;!-- Font Awesome --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/font-awesome/css/font-awesome.min.css&quot;)&quot;&gt; &lt;!-- PNotify --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/pnotify/pnotify.css&quot;)&quot;&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/pnotify/pnotify.nonblock.css&quot;)&quot;&gt; &lt;!-- query-builder --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/jQuery-QueryBuilder/css/query-builder.default.min.css&quot;)&quot;&gt; &lt;link rel=&quot;shortcut icon&quot; type=&quot;image/png&quot; href=&quot;@routes.Assets.versioned(&quot;images/favicon.png&quot;)&quot;&gt; &lt;!--DataTable dependencies --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/datatables/dataTables.bootstrap.min.css&quot;)&quot;&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/datatables/buttons.dataTables.min.css&quot;)&quot;&gt; &lt;!-- jQuery UI --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/jquery-ui/jquery-ui.css&quot;)&quot;&gt; &lt;!-- Boostrap DateTime-Picker --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/bootstrap-datetimepicker/bootstrap-datetimepicker.min.css&quot;)&quot;&gt; &lt;!-- iCheck --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/iCheck/all.css&quot;)&quot;&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;lib/iCheck/square/blue.css&quot;)&quot;&gt; &lt;!-- Main CSS: Bootstrap + AdminLTE + Custom css --&gt; &lt;link rel=&quot;stylesheet&quot; media=&quot;screen&quot; href=&quot;@routes.Assets.versioned(&quot;stylesheets/main.min.css&quot;)&quot;&gt; &lt;/head&gt; &lt;body style=&quot;height:auto;&quot; class=&quot;skin-darkblue-light fixed home-page&quot;&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;@routes.Assets.versioned(&quot;lib/mxgraph2/js/mxClient.js&quot;)&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;@routes.Assets.versioned(&quot;editor/editor.js&quot;)&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;@routes.Assets.versioned(&quot;editor/graph.js&quot;)&quot;&gt;&lt;/script&gt; &lt;div class=&quot;container&quot;&gt; &lt;div module=&quot;HeaderModule&quot;&gt; @header() &lt;/div&gt; &lt;div module=&quot;MainModule&quot;&gt; &lt;div controller=&quot;HomeController&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;navbar-fixed-bottom&quot;&gt; @footer() &lt;/div&gt; &lt;/div&gt; &lt;script type=&quot;text/javascript&quot; data-main=&quot;@routes.Assets.versioned(&quot;javascripts/main&quot;)&quot; src=&quot;@routes.Assets.versioned(&quot;lib/requirejs/require.min.js&quot;)&quot;&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; After creating the template, you now need to create an endpoint to return this view and register it in the system. So, to create the endpoint you add a new controller at app &gt; controllers or add a function to an existent controller. In this example we will create a new controller called HomeController.java: public class HomeController extends Controller { @Security.Authenticated(Secured.class) public Result index() { return ok(views.html.home.render()); } } And, then, to register it, add to: 1. conf &gt; routes: ... GET /home controllers.HomeController.index() ... app &gt; controllers &gt; Application.java &gt; javascriptRoutes(): public Result javascriptRoutes() { response().setHeader(Http.HeaderNames.CONTENT_TYPE, &quot;text/javascript&quot;); return ok(JavaScriptReverseRouter.create(&quot;jsRoutes&quot;, ..., routes.javascript.HomeController.index(), ... )); } 4.3.3 Creation of a UI component (handlebars) Once the URL for the base view is configured, the next step is to create the functional files that handle frontend and backend of the UI element. So, we will create a folder home at app &gt; assets &gt; javascripts. Inside this folder create tho files: homeController.js and homeView.js. The homeController.js is responsible to handle the backend operations and should follow a structure similar to this: define(&#39;HomeController&#39;, [&#39;Controller&#39;, &#39;HomeView&#39;, &#39;Router&#39;, &#39;Institution&#39;, &#39;Task&#39;, &#39;Alert&#39;, &#39;jquery&#39;, &#39;jsRoutes&#39;, &#39;jquery-cookie&#39;], function (Controller, HomeView, Router, Institution, Task, Alert, $, jsRoutes) { const HomeController = function (module) { Controller.call(this, module, new HomeView(this)); }; // Inheritance from the superclass HomeController.prototype = Object.create(Controller.prototype); const _super_ = Controller.prototype; HomeController.prototype.initialize = function ($container) { _super_.initialize.call(this, $container); this.getTasks(); }; HomeController.prototype.getTasks = function () { const context = this; Institution.getInstitutions(function (institutions) { context.view.loadInstitutions(institutions); }); }; return HomeController; }); On the other hand, the homeView.jsis responsible for frontend interactions and should follow a structure similar to: define(&#39;HomeView&#39;, [&#39;jquery&#39;, &#39;View&#39;], function ($, View) { const HomeView = function (controller) { View.call(this, controller, &#39;home&#39;); }; // Inheritance from super class HomeView.prototype = Object.create(View.prototype); const _super_ = View.prototype; HomeView.prototype.initialize = function ($container) { _super_.initialize.call(this, $container); }; HomeView.prototype.loadInstitutions = function (institutions) { const html = JST[&#39;home&#39;]({ institutions: institutions }); this.$container.html(html); this._loadViewComponents(); }; return HomeView; }); As can be seen in this last code snippet, we “import” a web (HTML) structure from 'home'. This refers to the file home.handlebars that must be placed at app &gt; assets &gt; templates. Hence, we will create this exact file in the specified location with the following content: &lt;div class=&quot;main-div&quot;&gt; &lt;div class=&quot;title&quot;&gt; &lt;h1&gt;&lt;b&gt;&lt;i class=&quot;fa fa-hospital-o&quot;&gt;&lt;/i&gt; Dashboard: Resources&lt;/b&gt;&lt;/h1&gt; &lt;/div&gt; &lt;div id=&quot;institutions&quot; view-element=&quot;institutions&quot; class=&quot;row&quot;&gt; {{#institutions}} &lt;div class=&quot;institution col-lg-4&quot;&gt; &lt;div class=&quot;panel panel-default&quot;&gt; &lt;div class=&quot;panel-heading&quot;&gt; &lt;h3 class=&quot;panel-title&quot;&gt;&lt;b&gt;{{name}}&lt;/b&gt;&lt;/h3&gt; &lt;/div&gt; &lt;div class=&quot;panel-body&quot;&gt; &lt;ul class=&quot;treeview-menu&quot; data-widget=&quot;tree&quot;&gt; &lt;!-- Tasks --&gt; &lt;li class=&quot;treeview menu&quot;&gt; &lt;a name=&quot;tasks&quot;&gt; &lt;i class=&quot;fa fa-folder&quot;&gt;&lt;/i&gt; &lt;span&gt;Tasks&lt;/span&gt; &lt;span class=&quot;pull-right-container&quot;&gt; &lt;i class=&quot;fa fa-angle-left pull-right&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;/a&gt; &lt;ul class=&quot;treeview-menu&quot;&gt; {{#tasks}} &lt;li&gt; &lt;a &lt;i class=&quot;fa fa-file-text-o&quot;&gt;&lt;/i&gt; &lt;span&gt;{{name}}&lt;/span&gt; &lt;/a&gt; &lt;/li&gt; {{/tasks}} &lt;li&gt; &lt;form class=&quot;sidebar-form&quot;&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;input name=&quot;taskName&quot; class=&quot;form-control&quot; placeholder=&quot;Create a new task...&quot;/&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-flat&quot;&gt; &lt;i class=&quot;fa fa-plus-circle&quot;&gt;&lt;/i&gt; &lt;/button&gt; &lt;/span&gt; &lt;/div&gt; &lt;/form&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; {{/institutions}} &lt;/div&gt; &lt;/div&gt; The next step is to tell the system where the newly-created resources are. So, at app &gt; assets &gt; javacripts &gt; main.js add the following: requirejs.config({ baseUrl: &#39;/assets/javascripts&#39;, paths: { ..., // Home &#39;HomeController&#39;: &#39;home/controllers/homeController&#39;, &#39;HomeView&#39;: &#39;home/views/homeView&#39;, ... }, ... }); var DEBUG = true; require([&#39;Application&#39;], function (Application) { window.app = new Application(); }); Last, but not least, we have to create the RegExp handler, as said earlier, so the system know what controllers and tools to load in the specific UI stage, at app &gt; assets &gt; application &gt; application.js: define(&#39;Application&#39;, [&#39;jquery&#39;, &#39;Router&#39;, &#39;Module&#39;, &#39;jsRoutes&#39;, &#39;Svg&#39;, &#39;Institution&#39;, &#39;adminLTE&#39;, &#39;custom.jquery&#39;], function ($, Router, Module, jsRoutes, Svg, Institution) { ... Application.prototype.initialize = function () { var self = this; // Configure router Router.config({mode: &#39;history&#39;}); // Add routes Router .add(new RegExp(jsRoutes.controllers.login.Login.index().url.substr(1), &#39;i&#39;), function () { console.log(&quot;LOGIN PAGE&quot;); }) ... .add(new RegExp(jsRoutes.controllers.HomeController.index().url.substr(1), &#39;i&#39;), function () { console.log(&quot;homepage&quot;); self.loadControllers(&#39;MainModule&#39;, [&#39;HomeController&#39;]); }); }; ... return Application; }); With this, we will be able to have a web page similar to this image, based on an entirely new HTML template: Figure 4.1: New HTML view created using a new UI component following the handlebars pattern. 4.4 Adding new PDI step Adding and registering a new Pentaho Data Integration Step is a straightforward process which has been streamlined by the design of the BICenter project. A list of all available PDI Steps can be found in this link. After selecting the Step to be added, the following is the process required to add said step into the system. Register the new step on the public &gt; editor &gt; diagrameditor.xml file. Add a new object to conf &gt; configuration.json under the subsection pertaining to the new component’s type with the desired component properties. If necessary, add extra functionality to the submitClick method on the app &gt; assets &gt; javascripts &gt; step &gt; stepController.js or the applyChanges method on app &gt; assets &gt; javascripts &gt; services &gt; step.js. Create a new class on app &gt; diSdk &gt; step &gt; parser with the appropriate name. If the component requires pre-processing or extra logic you can alter the decodeStep method on app &gt; diSdk &gt; step &gt; AbstractStep.java 4.4.1 Example The following is an example of how to add the CSVFileInput component. For more information about this component’s functioning you can check out this link. Firstly, we have to add the following line to public &gt; editor &gt; diagrameditor.xml &lt;add as=&quot;CSV File Input&quot; template=&quot;CSVInput&quot; icon=&quot;/assets/images/editor/rectangle.gif&quot;/&gt; Next we’ll have to register the component’s properties on the conf &gt; configuration.json file. As the CSV File Input step is an Input type component, we’ll be registering it under the Input Components. We’ll be naming this object the same name we used on the template field on the prior step. Note that the shortName field should have a name that goes in accordance with the naming specified by the Pentaho Kettle library (in our specific case, this can be seen in this link). Under the componentProperties array we can specify the multiple inputs and fields of our component. { &quot;name&quot;: &quot;CSVInput&quot;, &quot;description&quot;: &quot;CSV File Input&quot;, &quot;shortName&quot;: &quot;csvInput&quot;, &quot;componentProperties&quot;: [ { &quot;name&quot;: &quot;Step Name&quot;, &quot;shortName&quot;: &quot;stepName&quot;, &quot;type&quot;: &quot;input&quot; }, { &quot;name&quot;: &quot;File Name&quot;, &quot;shortName&quot;: &quot;fileName&quot;, &quot;type&quot;: &quot;fileinput&quot; }, { &quot;name&quot;: &quot;Delimiter&quot;, &quot;shortName&quot;: &quot;delimiter&quot;, &quot;type&quot;: &quot;input&quot; }, { &quot;name&quot;: &quot;Enclosure&quot;, &quot;shortName&quot;: &quot;enclosure&quot;, &quot;type&quot;: &quot;input&quot; }, { &quot;name&quot;: &quot;NIO Buffer Size&quot;, &quot;shortName&quot;: &quot;bufferSize&quot;, &quot;type&quot;: &quot;number&quot; }, { &quot;name&quot;: &quot;File Encoding&quot;, &quot;shortName&quot;: &quot;encoding&quot;, &quot;type&quot;: &quot;select&quot;, &quot;componentMetadatas&quot;: [ { &quot;value&quot;: &quot;UTF-8&quot;, &quot;name&quot;: &quot;UTF-8&quot; }, { &quot;value&quot;: &quot;ANSI&quot;, &quot;name&quot;: &quot;ANSI&quot; } ] }, { &quot;name&quot;: &quot;Lazy Conversion?&quot;, &quot;shortName&quot;: &quot;lazyConversionActive&quot;, &quot;type&quot;: &quot;checkbox&quot; } ] } } As BICenter is already prepared to receive files and all of our CSVInput’s parameters, we can skip this step. Now we have to create a new class on the app &gt; diSdk &gt; step &gt; parser directory. This can simply be done by copying any of the other classes already present in the folder. Don’t worry about the lack of logic in this class, as this serves as a mere extension of the AbstractStep class, which itself contains all logic needed to communicate with the PDI, used in order to allow our component to be detected and processed. package diSdk.step.parser; import diSdk.step.AbstractStep; import models.Step; import org.pentaho.di.trans.step.StepMetaInterface; import org.w3c.dom.Element; public class CSVInput extends AbstractStep { @Override public void decode(StepMetaInterface stepMetaInterface, Step step) throws Exception { } @Override public Element encode(StepMetaInterface stepMetaInterface) throws Exception { return null; } } As we want our system to automatically detect the CSV’s fields automatically without the users having to manually introduce them themselves, we have to add some logic to the decodeStep method on app &gt; diSdk &gt; step &gt; AbstractStep.java which will do an initial read of the file in order to extrapolate it’s columns’ names. This can be done by creating a new method on this class and adding it to the decodeStep method, or by injecting the logic directly into the function. // If dealing with CSVFileInput get the input fields and define them if (shortName.equals(&quot;InputFields&quot;)) { if (fileName == null) { Optional&lt;StepProperty&gt; fileNameStepProperty = stepProperties.stream() .filter(stepProperty -&gt; stepProperty.getComponentProperty().getShortName().equalsIgnoreCase(&quot;Filename&quot;)) .findFirst(); if (!fileNameStepProperty.isPresent()) continue; fileName = fileNameStepProperty.get().getValue(); } if (delimiter == null) { Optional&lt;StepProperty&gt; delimiterStepProperty = stepProperties.stream() .filter(stepProperty -&gt; stepProperty.getComponentProperty().getShortName().equalsIgnoreCase(&quot;Delimiter&quot;)) .findFirst(); if (!delimiterStepProperty.isPresent()) continue; delimiter = delimiterStepProperty.get().getValue(); } try { BufferedReader br = new BufferedReader(new FileReader(fileName)); String header = br.readLine(); String[] fields = new String[0]; if (header != null) { fields = header.split(delimiter); } TextFileInputField[] value = new TextFileInputField[fields.length]; for (int i = 0; i &lt; fields.length; i++) { String field = fields[i]; value[i] = new TextFileInputField(); value[i].setName(field); System.out.println(field); } // Invoke the current method with the StepProperty value. invokeMethod(stepMetaInterface, method, value, databases); } catch (FileNotFoundException e) { } "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
